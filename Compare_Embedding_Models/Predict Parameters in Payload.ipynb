{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#imports \r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.spatial import distance_matrix as get_dm\r\n",
    "from numba import njit, prange"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import JSON data\r\n",
    "\r\n",
    "with open(\"2021_05_25_apis/allEndpoints.json\",\"r\",encoding=\"utf-8\") as json_file:\r\n",
    "     apis = json.load(json_file)\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Number of APIs: \",len(apis))\r\n",
    "#calculate number of endpoints\r\n",
    "endpoint_lens = [len(apis[i][\"endpoints\"]) for i in range(len(apis))]\r\n",
    "print(\"Total number of Endpoints: \",sum(endpoint_lens))\r\n",
    "print(\"AVG number of Endpoints: \", sum(endpoint_lens)/len(apis))\r\n",
    "apis[2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Datastructures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import operator\r\n",
    "\r\n",
    "\r\n",
    "def string_to_list(value):\r\n",
    "        s_list = list(value)\r\n",
    "        out_list = []\r\n",
    "        for i in range(len(s_list)):\r\n",
    "            if operator.contains('!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',s_list[i]):\r\n",
    "                out_list.append('.')\r\n",
    "            else:\r\n",
    "                if s_list[i].isupper():\r\n",
    "                    out_list.append('.')\r\n",
    "                    out_list.append(s_list[i].lower())\r\n",
    "                else:\r\n",
    "                    out_list.append(s_list[i])\r\n",
    "\r\n",
    "        out_string = \"\".join(out_list)\r\n",
    "        return [x for x in out_string.split('.') if x]\r\n",
    "    \r\n",
    "\r\n",
    "class Api:\r\n",
    "    def __init__(self,api_data):\r\n",
    "        self._raw_data = api_data\r\n",
    "        self.key = api_data[\"key\"]\r\n",
    "        self.name = api_data[\"name\"]\r\n",
    "        self.version_key = api_data[\"versionKey\"]\r\n",
    "        self.version_name = api_data[\"versionName\"]\r\n",
    "        self.endpoints = [Endpoint(api_data[\"endpoints\"][i],i) for i in range(len(api_data[\"endpoints\"]))]\r\n",
    "    \r\n",
    "    def get_property(self,name):\r\n",
    "        return self._raw_data[name]\r\n",
    "    \r\n",
    "    def has_endpoints(self):\r\n",
    "        return len(self.endpoints) != 0\r\n",
    "    \r\n",
    "    def __str__(self):\r\n",
    "        json_dict = {}\r\n",
    "        json_dict[\"name\"] = self.name\r\n",
    "        json_dict[\"key\"] = self.key\r\n",
    "        json_dict[\"version_name\"] = self.version_name\r\n",
    "        json_dict[\"version_key\"] = self.version_key\r\n",
    "        json_dict[\"endpoints_size\"] = len(self.endpoints)\r\n",
    "        return json.dumps(json_dict)\r\n",
    "    \r\n",
    "        \r\n",
    "    \r\n",
    "    \r\n",
    "        \r\n",
    "class Endpoint:\r\n",
    "    def __init__(self,endpoint_data,endpoint_num):\r\n",
    "        self._raw_data = endpoint_data\r\n",
    "        self.path = endpoint_data[\"path\"]\r\n",
    "        self.method = endpoint_data[\"method\"]\r\n",
    "        self.request_parameters = [Parameter(endpoint_data[\"requestParameters\"][i]) for i in range(len(endpoint_data[\"requestParameters\"]))]\r\n",
    "        self.response_parameters = [Parameter(endpoint_data[\"responseParameters\"][i]) for i in range(len(endpoint_data[\"responseParameters\"]))]\r\n",
    "        self.path_list = self.path_to_list()\r\n",
    "        self.num = endpoint_num\r\n",
    "    \r\n",
    "    def get_property(self,name):\r\n",
    "        return self._raw_data[name]\r\n",
    "    \r\n",
    "    def has_parameters(self):\r\n",
    "        return (len(self.request_parameters) != 0 or len(self.response_parameters) != 0)\r\n",
    "    \r\n",
    "    def path_to_list(self):\r\n",
    "        return string_to_list(self.path)\r\n",
    "    \r\n",
    "    def __str__(self):\r\n",
    "        json_dict = {}\r\n",
    "        json_dict[\"method\"] = self.method\r\n",
    "        json_dict[\"path\"] = self.path\r\n",
    "        json_dict[\"request_parameters_size\"] = len(self.request_parameters)\r\n",
    "        json_dict[\"response_parameters_size\"] = len(self.response_parameters)\r\n",
    "        return json.dumps(json_dict)\r\n",
    "    \r\n",
    "class Parameter:\r\n",
    "    def __init__(self,parameter_data):\r\n",
    "        self._raw_data = parameter_data\r\n",
    "        self.xpath = parameter_data[\"xpath\"]\r\n",
    "        self.name = parameter_data[\"name\"]\r\n",
    "        \r\n",
    "        #if xpath is empty, overwrite it with name\r\n",
    "        if not self.xpath:\r\n",
    "            self.xpath = self.name\r\n",
    "            \r\n",
    "        self.xpath_list = self.xpath_to_list()\r\n",
    "        self.name_list = self.name_to_list()\r\n",
    "    \r\n",
    "    def get_property(self,name):\r\n",
    "        return self._raw_data[name]\r\n",
    "    \r\n",
    "    def name_to_list(self):\r\n",
    "        return string_to_list(self.name)\r\n",
    "        \r\n",
    "    def xpath_to_list(self):\r\n",
    "        return string_to_list(self.xpath)\r\n",
    "    \r\n",
    "    def __str__(self):\r\n",
    "        json_dict = {}\r\n",
    "        json_dict[\"name\"] = self.name\r\n",
    "        json_dict[\"xpath\"] = self.xpath\r\n",
    "        json_dict[\"name_list\"] = self.name_list\r\n",
    "        json_dict[\"xpath_list\"] = self.xpath_list\r\n",
    "        return json.dumps(json_dict)\r\n",
    "    \r\n",
    "    \r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apis_list = [Api(apis[i]) for i in range(len(apis))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test: print data for one api\r\n",
    "api = 2\r\n",
    "\r\n",
    "#Some tests:\r\n",
    "print(\"API:\")\r\n",
    "print(apis_list[api])\r\n",
    "print()\r\n",
    "print(\"Endpoints:\")\r\n",
    "\r\n",
    "for endpoint in apis_list[api].endpoints:\r\n",
    "    print(\"Endpoint:\")\r\n",
    "    print(endpoint)\r\n",
    "    print()\r\n",
    "    print(\"request parameters:\")\r\n",
    "    for rp in endpoint.request_parameters:\r\n",
    "        print(rp)\r\n",
    "    print()\r\n",
    "    print(\"response parameters:\")\r\n",
    "    for rp in endpoint.response_parameters:\r\n",
    "        print(rp)\r\n",
    "    print()\r\n",
    "    print()\r\n",
    "    \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Embeddings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# functions to load embeddings from file\r\n",
    "\r\n",
    "def load_embedding_from_json(file_path:str):    \r\n",
    "    with open(file_path,\"r\",encoding=\"utf-8\") as json_file:\r\n",
    "         word_embedding = json.load(json_file)       \r\n",
    "    # convert vectors from list to np array\r\n",
    "    for key, vector in word_embedding.items():\r\n",
    "        word_embedding[key] = np.array(vector)\r\n",
    "    return word_embedding\r\n",
    "\r\n",
    "def load_glove_embedding_from_file(file_path):\r\n",
    "    df = pd.read_csv(file_path, sep=\" \", quoting=3, header=None, index_col=0)\r\n",
    "    glove = {key: val.values for key, val in df.T.items()}\r\n",
    "    return glove"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load open api embedding \r\n",
    "api_embedding = load_embedding_from_json(\"saved_embeddings/open_api_embedding_5d_314_words.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#load glove embedding\r\n",
    "glove_embedding = load_glove_embedding_from_file(\"saved_embeddings/glove.6B.50d.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reduce Glove Embedding to same Vocabulary as OpenAPI Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_words_and_vectors_from_embedding(embedding: dict):\r\n",
    "    words = []\r\n",
    "    vectors = []\r\n",
    "    \r\n",
    "    for word, vector in embedding.items():\r\n",
    "        words.append(word)\r\n",
    "        vectors.append(vector)\r\n",
    "    \r\n",
    "    return words, np.array(vectors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "api_embedding_words, api_embedding_vectors = extract_words_and_vectors_from_embedding(api_embedding)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def reduce_embedding_to_words(embedding: dict, words: list):\r\n",
    "    reduced_embedding = {}\r\n",
    "    for w in words:\r\n",
    "        try:\r\n",
    "            vector = embedding[w]\r\n",
    "            reduced_embedding[w] = vector\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "    return reduced_embedding    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# reduce glove embedding to the same words as api embedding\r\n",
    "glove_embedding = reduce_embedding_to_words(glove_embedding, api_embedding_words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Size own embedding: \"+str(len(api_embedding)))\r\n",
    "print(\"Size glove embedding: \"+str(len(glove_embedding)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"M2M embedding / Glove Embedding\")\r\n",
    "\r\n",
    "for key, value in api_embedding.items():\r\n",
    "    try:\r\n",
    "        a = glove_embedding[key]\r\n",
    "    except:\r\n",
    "        print(key)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Datastructure for Requests "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Request:\r\n",
    "    def __init__(self, endpoint_name:str, method:str, parameters:list):\r\n",
    "        self.endpoint = endpoint_name\r\n",
    "        self.method = method\r\n",
    "        self.parameters = parameters\r\n",
    "        \r\n",
    "    def __str__(self):\r\n",
    "        json_dict = {}\r\n",
    "        json_dict[\"endpoint\"] = self.endpoint\r\n",
    "        json_dict[\"method\"] = self.method\r\n",
    "        json_dict[\"parameters\"] = self.parameters\r\n",
    "        return json.dumps(json_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = Request(\"mein endpoint\", \"post\", [\"das\", \"hier\", \"ist\", \"schoen\"])\r\n",
    "\r\n",
    "print(a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Request Object for requests that are completely embedded "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "def create_request_obj_if_embedded(embedding:dict, endpoint, min_words:int):\r\n",
    "    is_suitable = True\r\n",
    "    parameter_words = []\r\n",
    "    for request_parameter in endpoint.request_parameters:\r\n",
    "        for word in request_parameter.xpath_list:\r\n",
    "            if word in embedding:\r\n",
    "                parameter_words.append(word)\r\n",
    "            else:\r\n",
    "                is_suitable = False\r\n",
    "                break\r\n",
    "        if not is_suitable:\r\n",
    "            break\r\n",
    "    \r\n",
    "    parameter_words = list(set(parameter_words))\r\n",
    "    \r\n",
    "    if len(parameter_words) < min_words:\r\n",
    "        is_suitable = False        \r\n",
    "    \r\n",
    "    if is_suitable:\r\n",
    "        request_obj = Request(endpoint.path[1:], endpoint.method, parameter_words)\r\n",
    "    else:\r\n",
    "        request_obj = None\r\n",
    "        \r\n",
    "    return is_suitable, request_obj"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "requests = []\r\n",
    "\r\n",
    "for api in apis_list:\r\n",
    "    for endpoint in api.endpoints:\r\n",
    "        is_embedded, request_obj = create_request_obj_if_embedded(glove_embedding, endpoint, min_words=4)\r\n",
    "        \r\n",
    "        if is_embedded:\r\n",
    "            requests.append(request_obj)\r\n",
    "        \r\n",
    "len(requests)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(requests[5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from functools import cmp_to_key\r\n",
    "def compare(item1, item2):\r\n",
    "    if len(item1.parameters) < len(item2.parameters):\r\n",
    "        return 1\r\n",
    "    elif len(item1.parameters) > len(item2.parameters):\r\n",
    "        return -1\r\n",
    "    else:\r\n",
    "        return 0\r\n",
    "    \r\n",
    "requests.sort(key=cmp_to_key(compare))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(requests[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduce Glove to 5 Dimensions with PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "glove_embedding_words, glove_embedding_vectors = extract_words_and_vectors_from_embedding(glove_embedding)\r\n",
    "\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "pca = PCA(n_components = 5)\r\n",
    "glove_embedding_vectors = pca.fit_transform(glove_embedding_vectors)\r\n",
    "\r\n",
    "def create_embedding_dict(embedding_words, embedding_vectors):\r\n",
    "    embedding = {}\r\n",
    "    \r\n",
    "    for i in range(len(embedding_words)):\r\n",
    "        embedding[embedding_words[i]] = embedding_vectors[i]\r\n",
    "        \r\n",
    "    return embedding\r\n",
    "\r\n",
    "glove_embedding = create_embedding_dict(glove_embedding_words, glove_embedding_vectors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict next words by Distance in Vector Space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial import distance\r\n",
    "from functools import cmp_to_key\r\n",
    "\r\n",
    "def get_next_words(known_words:list, embedding: dict):\r\n",
    "    def get_wordlist_distance_to_point(center_point, embedding:dict, known_words:list):\r\n",
    "        words = [] # list of elements (word, distance)\r\n",
    "        for word, vector in embedding.items():\r\n",
    "            if word not in known_words:\r\n",
    "                words.append((distance.euclidean(center_point, vector), word))\r\n",
    "        return words\r\n",
    "            \r\n",
    "    def compare(item):\r\n",
    "            return item[0]\r\n",
    "    \r\n",
    "    center_point = embedding[known_words[0]]\r\n",
    "    for i in range(1, len(known_words)):\r\n",
    "        center_point = np.add(center_point, embedding[known_words[i]])\r\n",
    "    center_point = center_point/len(known_words)\r\n",
    "    \r\n",
    "    words = get_wordlist_distance_to_point(center_point, embedding, known_words)    \r\n",
    "    list.sort(words, key=compare)\r\n",
    "    \r\n",
    "    return words "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_prediction_result(request, number_known_words:int, embedding:dict):\r\n",
    "    known_words = request.parameters[:number_known_words]\r\n",
    "    words_to_predict = request.parameters[number_known_words:]\r\n",
    "    \r\n",
    "    prediction_order = [i[1] for i in get_next_words(known_words, embedding)]\r\n",
    "    \r\n",
    "    prediction_delay = [max(0, prediction_order.index(w)-len(words_to_predict)+1) for w in words_to_predict]\r\n",
    "    \r\n",
    "    number_correct = 0\r\n",
    "    for i in prediction_delay:\r\n",
    "        if i==0:\r\n",
    "            number_correct += 1\r\n",
    "            \r\n",
    "    return number_correct/len(prediction_delay), sum(prediction_delay)/len(prediction_delay)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "\r\n",
    "req = requests[1]\r\n",
    "num_param_in_reqest = len(req.parameters)\r\n",
    "known = random.randint(1, num_param_in_reqest-1)\r\n",
    "\r\n",
    "portion_correct_api, avg_delay_api_embedding = get_prediction_result(req, known, api_embedding)\r\n",
    "portion_correct_glove, avg_delay_glove_embedding = get_prediction_result(req, known, glove_embedding)\r\n",
    "\r\n",
    "print(\"portion correct own embedding: \"+str(portion_correct_api))\r\n",
    "print(\"avg delay own embedding: \"+str(avg_delay_api_embedding))\r\n",
    "print()\r\n",
    "print(\"portion correct glove embedding: \"+str(portion_correct_glove))\r\n",
    "print(\"avg delay glove embedding: \"+str(avg_delay_glove_embedding))\r\n",
    "print()\r\n",
    "print(\"known: \"+str(known))\r\n",
    "print(\"num_param_in_reqest: \"+str(num_param_in_reqest))\r\n",
    "print()\r\n",
    "print(\"known parameters: \"+str(req.parameters[:known]))\r\n",
    "print(\"parameters to predict : \"+str(req.parameters[known:]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import math\r\n",
    "\r\n",
    "error_own_embedding = []\r\n",
    "error_glove_embedding = []\r\n",
    "\r\n",
    "number_known_parameters = [] \r\n",
    "number_total_parameters = [] \r\n",
    "\r\n",
    "for request in requests:\r\n",
    "    known = math.floor(len(request.parameters)/2)\r\n",
    "    portion_correct_api, avg_delay_api_embedding = get_prediction_result(request, known, api_embedding)\r\n",
    "    portion_correct_glove, avg_delay_glove_embedding = get_prediction_result(request, known, glove_embedding)\r\n",
    "\r\n",
    "    number_known_parameters.append(known)\r\n",
    "    number_total_parameters.append(len(request.parameters))\r\n",
    "\r\n",
    "    error_own_embedding.append(avg_delay_api_embedding)\r\n",
    "    error_glove_embedding.append(avg_delay_glove_embedding)\r\n",
    "\r\n",
    "print(\"avg known: \"+str(sum(number_known_parameters)/len(number_known_parameters)))\r\n",
    "print(\"avg total: \"+str(sum(number_total_parameters)/len(number_total_parameters)))\r\n",
    "    \r\n",
    "print(\"avg delay own embedding: \"+str(sum(error_own_embedding)/len(error_own_embedding)))\r\n",
    "print(\"avg delay glove embedding: \"+str(sum(error_glove_embedding)/len(error_glove_embedding)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction with NN "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Requests into Training and Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "requests_train, requests_test = train_test_split(requests, test_size = 0.2, random_state = 0, shuffle=True)\r\n",
    "\r\n",
    "print(\"len all requests \"+str(len(requests)))\r\n",
    "print(\"len requests train \"+str(len(requests_train)))\r\n",
    "print(\"len requests test \"+str(len(requests_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Map Word to Index in One-Hot Vector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_word_to_index_dict(wordlist:list):\r\n",
    "    res = {}\r\n",
    "    for i, word in enumerate(wordlist):\r\n",
    "        res[word] = i\r\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make word -> index dict\r\n",
    "index_of_word_glove = get_word_to_index_dict(glove_embedding_words)\r\n",
    "index_of_word_api = get_word_to_index_dict(api_embedding_words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Training Data API Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# all possible subsets of size k\r\n",
    "def get_all_possible_subsets_of_length_k(number_to_choose_k:int, size_of_list_to_choose_from_n:int):\r\n",
    "    '''returns all combinations of (number_to_choose_k) indices in List with size (size_of_list_to_choose_from_n)'''\r\n",
    "    def get_next_combination(current_combination):\r\n",
    "        def move_later_indices_to_min_value(index_in_combination_just_set:int, current_combination):\r\n",
    "            value_just_set = current_combination[index_in_combination_just_set]\r\n",
    "            for i in range(1, len(current_combination) - index_in_combination_just_set):\r\n",
    "                current_combination[index_in_combination_just_set+i] = value_just_set+i\r\n",
    "            return current_combination\r\n",
    "        \r\n",
    "        for pos in range(len(current_combination)-1, -1, -1): # iterate backwards through list\r\n",
    "            pos_value = current_combination[pos]\r\n",
    "            if pos_value+1 < size_of_list_to_choose_from_n and pos_value+1 not in current_combination:\r\n",
    "                current_combination[pos] += 1\r\n",
    "                current_combination = move_later_indices_to_min_value(pos, current_combination)\r\n",
    "                break\r\n",
    "        return current_combination\r\n",
    "\r\n",
    "    sets = []\r\n",
    "    combination = [i for i in range(number_to_choose_k)]\r\n",
    "    last_combination = [i for i in range(size_of_list_to_choose_from_n-number_to_choose_k, size_of_list_to_choose_from_n)]\r\n",
    "\r\n",
    "    sets.append(combination.copy())\r\n",
    "    while combination != last_combination:\r\n",
    "        combination = get_next_combination(combination)\r\n",
    "        sets.append(combination.copy())\r\n",
    "    return np.array(sets)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_all_possible_subsets_of_length_k(3, 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get_data_and_wanted results from requests\r\n",
    "\r\n",
    "def get_data_for_training(requests, embedding:dict, index_of_word_dict: dict):\r\n",
    "    def get_one_hot_output(words:list, index_of_word_dict: dict, size:int):\r\n",
    "        one_hot = np.zeros(size, dtype=np.float32)\r\n",
    "        for w in words:\r\n",
    "            one_hot[index_of_word_dict[w]] = 1\r\n",
    "        return one_hot\r\n",
    "\r\n",
    "    def get_input(words:list, embedding:dict):\r\n",
    "        input = []\r\n",
    "        for i in range(3):\r\n",
    "            try:\r\n",
    "                vector = embedding[words[i]]\r\n",
    "            except:\r\n",
    "                vector = np.zeros(5)\r\n",
    "            \r\n",
    "            input.append(vector)\r\n",
    "\r\n",
    "        # result are all permutations\r\n",
    "        result = np.array([np.concatenate((input[0],input[1],input[2])),\r\n",
    "                           np.concatenate((input[0],input[2],input[1])),\r\n",
    "                           np.concatenate((input[1],input[0],input[2])),\r\n",
    "                           np.concatenate((input[1],input[2],input[1])),\r\n",
    "                           np.concatenate((input[2],input[0],input[1])),\r\n",
    "                           np.concatenate((input[2],input[1],input[0]))])\r\n",
    "        return result\r\n",
    "\r\n",
    "    input_data = []\r\n",
    "    labels = []\r\n",
    "    size_output = len(embedding)\r\n",
    "\r\n",
    "    for req in requests:\r\n",
    "        param = req.parameters\r\n",
    "\r\n",
    "        index_variants_known_words = get_all_possible_subsets_of_length_k(3, len(param))\r\n",
    "\r\n",
    "        for indexes in index_variants_known_words:\r\n",
    "            w0 = param[indexes[0]]\r\n",
    "            w1 = param[indexes[1]]\r\n",
    "            w2 = param[indexes[2]]\r\n",
    "            words = [w0, w1, w2]\r\n",
    "\r\n",
    "            new_inputs = get_input(words, embedding)\r\n",
    "\r\n",
    "            # len(new_inputs) should be 6 (permutation of 3 input embeddings)\r\n",
    "\r\n",
    "            words_to_predict = param.copy()\r\n",
    "            words_to_predict.remove(w0)\r\n",
    "            words_to_predict.remove(w1)\r\n",
    "            words_to_predict.remove(w2)\r\n",
    "\r\n",
    "            wanted_one_hot_output = get_one_hot_output(words_to_predict, index_of_word_dict, size_output)\r\n",
    "\r\n",
    "            for ni in new_inputs:\r\n",
    "                input_data.append(ni)\r\n",
    "                labels.append(wanted_one_hot_output)\r\n",
    "\r\n",
    "    return np.array(input_data), np.array(labels)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training / test data api embedding\r\n",
    "input_train_api, output_train_api = get_data_for_training(requests_train, api_embedding, index_of_word_api)\r\n",
    "input_test_api, output_test_api = get_data_for_training(requests_test, api_embedding, index_of_word_api)\r\n",
    "\r\n",
    "print(input_train_api.shape)\r\n",
    "print(output_train_api.shape)\r\n",
    "print()\r\n",
    "print(input_test_api.shape)\r\n",
    "print(output_test_api.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training / test data glove embedding\r\n",
    "input_train_glove, output_train_glove = get_data_for_training(requests_train, glove_embedding, index_of_word_api)\r\n",
    "input_test_glove, output_test_glove = get_data_for_training(requests_test, glove_embedding, index_of_word_api)\r\n",
    "\r\n",
    "print(input_train_glove.shape)\r\n",
    "print(output_train_glove.shape)\r\n",
    "print()\r\n",
    "print(input_test_glove.shape)\r\n",
    "print(output_test_glove.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shuffle api data\r\n",
    "random_seed = 42  # guarantees that input and labels are shuffeled in the same way\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(input_train_api)\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(output_train_api)\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(input_test_api)\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(output_test_api)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shuffle glove data\r\n",
    "random_seed = 42  # guarantees that input and labels are shuffeled in the same way\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(input_train_glove)\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(output_train_glove)\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(input_test_glove)\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(output_test_glove)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow.keras.backend as kb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#avg Number words to Predict\r\n",
    "\r\n",
    "numbers_words_to_predict = np.array([np.sum(i) for i in output_train_api])\r\n",
    "\r\n",
    "avg_number_words_to_predict = np.sum(numbers_words_to_predict)/len(numbers_words_to_predict)\r\n",
    "\r\n",
    "\r\n",
    "# factor for false negative prediction in Loss function\r\n",
    "# idea all 0 should get the same loss as all 1\r\n",
    "\r\n",
    "size_one_hot_output = (len(output_train_glove[0])+len(output_train_api[0]))/2\r\n",
    "\r\n",
    "factor_fn = size_one_hot_output/avg_number_words_to_predict\r\n",
    "\r\n",
    "factor_fn *= 0.5 #seemed to be to large\r\n",
    "\r\n",
    "print(avg_number_words_to_predict)\r\n",
    "print(factor_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def custom_loss(y_actual,y_pred):\r\n",
    "    custom_loss=kb.abs(y_actual-y_pred)*((factor_fn-1)*y_actual+1)\r\n",
    "    return custom_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model API Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "model_with_api_embedding.add(tf.keras.layers.Dense(units=15, activation='linear')) # input layer\r\n",
    "model_with_api_embedding.add(tf.keras.layers.Dense(units=128, activation='relu'))   # hidden layer\r\n",
    "model_with_api_embedding.add(tf.keras.layers.Dense(units=len(output_train_api[0]), activation='sigmoid')) # output layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Glove Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "model_with_glove_embedding.add(tf.keras.layers.Dense(units=15, activation='linear')) # input layer\r\n",
    "model_with_glove_embedding.add(tf.keras.layers.Dense(units=128, activation='relu'))   # hidden layer\r\n",
    "model_with_glove_embedding.add(tf.keras.layers.Dense(units=len(output_train_glove[0]), activation='sigmoid')) # output layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test / Train Classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_nn_prediction_result(res_predicted, res_actual, log=False):\r\n",
    "    prediction = []\r\n",
    "\r\n",
    "    for i, value in enumerate(res_predicted):\r\n",
    "        prediction.append([i, value])\r\n",
    "        \r\n",
    "\r\n",
    "    def sortkey(el):\r\n",
    "        return el[1]\r\n",
    "\r\n",
    "    prediction.sort(key=sortkey, reverse=True)\r\n",
    "    if log:\r\n",
    "        print(\"prediction order:\")\r\n",
    "        print(prediction)\r\n",
    "\r\n",
    "    prediction_order = [i[0] for i in prediction]\r\n",
    "\r\n",
    "    prediction = None # free ram\r\n",
    "    \r\n",
    "    indices_words_to_predict = [i for i in range(len(res_actual)) if res_actual[i]==1]\r\n",
    "\r\n",
    "    if log:\r\n",
    "        print(\"indices to predict: \"+str(indices_words_to_predict))\r\n",
    "\r\n",
    "    prediction_delays = [max(0, prediction_order.index(w)-len(indices_words_to_predict)+1) for w in indices_words_to_predict]\r\n",
    "\r\n",
    "    if log:\r\n",
    "        print(\"Prediction delays: \"+str(prediction_delays))\r\n",
    "\r\n",
    "    number_correct = 0\r\n",
    "    for i in prediction_delays:\r\n",
    "        if i==0:\r\n",
    "            number_correct += 1\r\n",
    "\r\n",
    "    portion_correct = number_correct/len(prediction_delays)\r\n",
    "    avg_delay = sum(prediction_delays)/len(prediction_delays)\r\n",
    "    \r\n",
    "    return portion_correct, avg_delay"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_avg_prediction_delay(predictions_outputs, wanted_outputs):\r\n",
    "    delays = []\r\n",
    "\r\n",
    "    for i in range(len(predictions_outputs)):\r\n",
    "        delays.append(get_nn_prediction_result(predictions_outputs[i], wanted_outputs[i])[1])\r\n",
    "\r\n",
    "    delays = np.array(delays)\r\n",
    "    avg_delay = np.sum(delays)/len(delays)\r\n",
    "\r\n",
    "    return avg_delay"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result without Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result without Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result 1 Epochs Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 1 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result after 2 Epochs Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 2 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result after 3 Epochs of Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 3 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result after 4 Epochs of Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 4 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result 5 Epochs of Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 8, epochs = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 5 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result after 100 Epochs of Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 6, epochs = 50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 6, epochs = 50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 100 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result after 200 Epochs of Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_glove_embedding.fit(input_train_glove, output_train_glove, batch_size = 8, epochs = 100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_with_api_embedding.fit(input_train_api, output_train_api, batch_size = 8, epochs = 100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test_api = model_with_api_embedding.predict(input_test_api)\r\n",
    "prediction_train_api = model_with_api_embedding.predict(input_train_api)\r\n",
    "\r\n",
    "prediction_test_glove = model_with_glove_embedding.predict(input_test_glove)\r\n",
    "prediction_train_glove = model_with_glove_embedding.predict(input_train_glove)\r\n",
    "\r\n",
    "print(\"Result after 200 Epochs of Training\")\r\n",
    "avg_delay_api_test = get_avg_prediction_delay(prediction_test_api, output_test_api)\r\n",
    "print(\"avg_delay_api_test: \"+str(avg_delay_api_test))\r\n",
    "avg_delay_glove_test = get_avg_prediction_delay(prediction_test_glove, output_test_glove)\r\n",
    "print(\"avg_delay_glove_test: \"+str(avg_delay_glove_test))\r\n",
    "avg_delay_api_train = get_avg_prediction_delay(prediction_train_api, output_train_api)\r\n",
    "print(\"avg_delay_api_train: \"+str(avg_delay_api_train))\r\n",
    "avg_delay_glove_train = get_avg_prediction_delay(prediction_train_glove, output_train_glove)\r\n",
    "print(\"avg_delay_glove_train: \"+str(avg_delay_glove_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "index = 8\r\n",
    "result = get_nn_prediction_result(prediction_test_api[index], output_test_api[index], log=True)\r\n",
    "print(\"result: \"+str(result))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "interpreter": {
   "hash": "640a24517a88fa39ef71434eb926794dc1d9497c7aa18429429cd6b5a4543668"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}